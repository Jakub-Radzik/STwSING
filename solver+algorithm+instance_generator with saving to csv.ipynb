{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1742e4a3-2747-418a-a564-89a5494d1a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ace_tools in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: gurobipy in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (12.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install ace_tools\n",
    "\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install ace_tools\n",
    "!{sys.executable} -m pip install gurobipy\n",
    "\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import pprint\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "import statistics\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import statistics\n",
    "epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0062c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def utility(x_r, w_r, gamma):\n",
    "    if gamma == 1:\n",
    "        return w_r * np.log(x_r)\n",
    "    else:\n",
    "        return (w_r / (1 - gamma)) * x_r**(1 - gamma)\n",
    "\n",
    "def measure_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        execution_times = []\n",
    "        results = []\n",
    "\n",
    "        for _ in range(3):\n",
    "            start_time = time.perf_counter()\n",
    "            result = func(*args, **kwargs)  # Wywołanie funkcji\n",
    "            end_time = time.perf_counter()\n",
    "\n",
    "            execution_times.append((end_time - start_time) * 1000)\n",
    "            results.append(result)\n",
    "\n",
    "        time_mean = statistics.mean(execution_times)  # Obliczenie średniego czasu\n",
    "        time_std_dev = statistics.stdev(execution_times)  # Obliczenie odchylenia standardowego\n",
    "        result_mean = statistics.mean(results)       # Obliczenie średniego wyniku\n",
    "\n",
    "        return time_mean, time_std_dev, result_mean\n",
    "    return wrapper\n",
    "\n",
    "def measure_time_solver(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        execution_times = []\n",
    "        results = []\n",
    "\n",
    "        for _ in range(3):\n",
    "            result_val, result_time = func(*args, **kwargs)  # Wywołanie funkcji\n",
    "\n",
    "            execution_times.append(result_time * 1000)\n",
    "            results.append(result_val)\n",
    "\n",
    "        time_mean = statistics.mean(execution_times)  # Obliczenie średniego czasu\n",
    "        time_std_dev = statistics.stdev(execution_times)  # Obliczenie odchylenia standardowego\n",
    "        result_mean = statistics.mean(results)       # Obliczenie średniego wyniku\n",
    "\n",
    "        return time_mean, time_std_dev, result_mean\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e11883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_initial_strategies_for_single_link(link_index, routing_matrix, capacity, weights, path_weights, gamma):\n",
    "    \"\"\"\n",
    "    Compute the allocation s_lr for a specific link.\n",
    "\n",
    "    Parameters:\n",
    "        link_index: Index of the link (l).\n",
    "        routing_matrix: np.array (L x R), where a[l][r] = 1 if flow r uses link l, else 0.\n",
    "        capacity: Capacity of the specific link (c_l).\n",
    "        weights: List of flow weights (w_r).\n",
    "        path_weights: List of path weights (b_r), either uniform or path-length-based.\n",
    "        gamma: Isoelastic parameter.\n",
    "\n",
    "    Returns:\n",
    "        strategies: List of s_lr values for the specific link (l), where s_lr is the allocation for each flow r.\n",
    "    \"\"\"\n",
    "    flows = routing_matrix.shape[1]\n",
    "    strategies = np.zeros(flows)\n",
    "\n",
    "    # Calculate the denominator: sum of (b_j w_j)^(1/gamma) for all flows using the link\n",
    "    denominator = sum(\n",
    "        routing_matrix[link_index][j] * (path_weights[j] * weights[j])**(1/gamma)\n",
    "        for j in range(flows)\n",
    "    )\n",
    "\n",
    "    for r in range(flows):  # Iterate over flows\n",
    "        if routing_matrix[link_index][r] == 1:  # Only allocate if flow r uses the link\n",
    "            # Numerator: (b_r w_r)^(1/gamma) for flow r\n",
    "            numerator = capacity * (path_weights[r] * weights[r])**(1/gamma)\n",
    "            # strategies for flow r on the specific link\n",
    "            strategies[r] = numerator / denominator\n",
    "\n",
    "    return strategies\n",
    "\n",
    "\n",
    "def compute_strategy_for_single_link_in_iteration(link_index, routing_matrix, capacity, weights, path_weights, gamma, non_saturated_flows, previous_strategies):\n",
    "    \"\"\"\n",
    "    Compute the allocation s_lr for a specific link in an iteration.\n",
    "    \"\"\"\n",
    "    flows = routing_matrix.shape[1]\n",
    "    strategies = np.zeros(flows)\n",
    "    saturated_flows = set(range(flows)) - non_saturated_flows\n",
    "\n",
    "    for r in saturated_flows:\n",
    "        if routing_matrix[link_index][r] == 1:\n",
    "            flow_capacity = min([previous_strategies[i][r] for i in range(routing_matrix.shape[0]) if routing_matrix[i][r] == 1])\n",
    "            strategies[r] = flow_capacity\n",
    "            capacity -= flow_capacity\n",
    "\n",
    "    # Calculate the denominator: sum of (b_j w_j)^(1/gamma) for all flows using the link\n",
    "    denominator = sum(\n",
    "        routing_matrix[link_index][j] * (path_weights[j] * weights[j])**(1/gamma)\n",
    "        for j in non_saturated_flows\n",
    "    )\n",
    "\n",
    "    for r in non_saturated_flows:  # Iterate over flows\n",
    "        if routing_matrix[link_index][r] == 1:  # Only allocate if flow r uses the link\n",
    "            # Numerator: (b_r w_r)^(1/gamma) for flow r\n",
    "            numerator = capacity * (path_weights[r] * weights[r])**(1/gamma)\n",
    "            # strategies for flow r on the specific link\n",
    "            strategies[r] = numerator / denominator\n",
    "\n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58cc1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time\n",
    "def capacity_allocation_game(links, capacities, routing_matrix, weights, gamma=1):\n",
    "    num_flows = len(weights)\n",
    "\n",
    "    strategies = [compute_initial_strategies_for_single_link(l, routing_matrix, capacities[l], weights, weights, gamma) for l in range(links)]\n",
    "    non_saturated_flows = set(range(num_flows))\n",
    "\n",
    "    links_that_run_out_of_capacity = [\n",
    "        l for l in range(links)\n",
    "        if math.isclose(\n",
    "            sum(\n",
    "                min([strategies[i][r] for i in range(links) if routing_matrix[i][r] == 1])\n",
    "                for r in range(num_flows)\n",
    "                if routing_matrix[l][r] == 1\n",
    "            ),\n",
    "            capacities[l],\n",
    "            rel_tol=epsilon\n",
    "        )\n",
    "    ]\n",
    "    n = 2\n",
    "    while n <= links:\n",
    "        iteration_saturated_flows = set([r for r in range(num_flows) if any(routing_matrix[l][r] == 1 for l in links_that_run_out_of_capacity)])\n",
    "        non_saturated_flows = non_saturated_flows - iteration_saturated_flows\n",
    "        new_strategies = [compute_strategy_for_single_link_in_iteration(l, routing_matrix, capacities[l], weights, weights, gamma, non_saturated_flows, strategies) for l in range(links)]\n",
    "        strategies = new_strategies\n",
    "        links_that_run_out_of_capacity = [\n",
    "            l for l in range(links)\n",
    "            if math.isclose(\n",
    "                sum(\n",
    "                    min([strategies[i][r] for i in range(links) if routing_matrix[i][r] == 1])\n",
    "                    for r in range(num_flows)\n",
    "                    if routing_matrix[l][r] == 1\n",
    "                ),\n",
    "                capacities[l],\n",
    "                rel_tol=epsilon\n",
    "            )\n",
    "        ]\n",
    "        n += 1\n",
    "        if len(non_saturated_flows) == 0:\n",
    "            break\n",
    "\n",
    "    network_utility = sum(utility(min([strategies[l][r] for l in range(links) if routing_matrix[l][r] == 1]), weights[r], gamma) for r in range(num_flows))\n",
    "\n",
    "\n",
    "    return network_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bf33d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@measure_time_solver\n",
    "def optimize_with_gurobi(capacities, routing_matrix, weights, gamma):\n",
    "    num_links = len(capacities)\n",
    "    num_flows = len(weights)\n",
    "    with gp.Env(empty=True) as env:\n",
    "        env.setParam('OutputFlag', 0)\n",
    "        env.start()\n",
    "        with gp.Model(env=env) as model:\n",
    "            # Create the model\n",
    "\n",
    "            # Decision variables: allocation for each flow on each link\n",
    "            x = model.addVars(num_links, num_flows, lb=0, name=\"x\")\n",
    "\n",
    "            # Objective: Maximize total utility (reformulated for Gurobi linear/quadratic constraints)\n",
    "            if gamma == 1:\n",
    "                aux_vars = model.addVars(num_flows, lb=0, name=\"aux\")\n",
    "                aux_min_vars = model.addVars(num_flows, lb=0, name=\"aux_min\")\n",
    "                aux_log_vars = model.addVars(num_flows, lb=1e-6, name=\"aux_log\")\n",
    "                aux_vars_prod = model.addVars(num_flows, lb=0, name=\"aux_prod\")\n",
    "\n",
    "                for r in range(num_flows):\n",
    "                    model.addConstr(aux_min_vars[r] == gp.min_([x[l, r] for l in range(num_links) if routing_matrix[l, r] == 1]),\n",
    "                                    name=f\"min_alloc_{r}\")\n",
    "\n",
    "                for r in range(num_flows):\n",
    "                    model.addConstr(aux_log_vars[r] == aux_min_vars[r] + 1e-6,\n",
    "                                    name=f\"log_alloc_{r}\")\n",
    "\n",
    "                for r in range(num_flows):\n",
    "                    model.addGenConstrLog(aux_log_vars[r], aux_vars[r], name=f\"aux_constraint_{r}\")\n",
    "\n",
    "                for r in range(num_flows):\n",
    "                    model.addConstr(aux_vars_prod[r] == aux_vars[r] * weights[r],\n",
    "                                    name=f\"prod_alloc_{r}\")\n",
    "\n",
    "                objective = gp.quicksum(aux_vars_prod[r]\n",
    "                                        for r in range(num_flows))\n",
    "                model.setObjective(objective, GRB.MAXIMIZE)\n",
    "\n",
    "\n",
    "            else:\n",
    "                aux_vars = model.addVars(num_flows, lb=0, name=\"aux\")\n",
    "                aux_min_vars = model.addVars(num_flows, lb=0, name=\"aux_min\")\n",
    "\n",
    "                for r in range(num_flows):\n",
    "                    model.addConstr(aux_min_vars[r] == gp.min_([x[l, r] for l in range(num_links) if routing_matrix[l, r] == 1]),\n",
    "                                    name=f\"min_alloc_{r}\")\n",
    "\n",
    "                for r in range(num_flows):\n",
    "                    model.addConstr(aux_vars[r] == (aux_min_vars[r] + 1e-6)**(1-gamma) , name=f\"aux_constraint_{r}\")\n",
    "                objective = gp.quicksum(weights[r] / (1 - gamma) * aux_vars[r]\n",
    "                                        for r in range(num_flows))\n",
    "                model.setObjective(objective, GRB.MAXIMIZE)\n",
    "\n",
    "            # Constraints\n",
    "            for l in range(num_links):\n",
    "                # Capacity constraint: sum of allocations on link l <= capacity\n",
    "                model.addConstr(gp.quicksum(x[l, r] for r in range(num_flows) if routing_matrix[l, r] == 1) <= capacities[l],\n",
    "                                name=f\"capacity_{l}\")\n",
    "\n",
    "            for r in range(num_flows):\n",
    "                # Flow constraint: sum of allocations across links for flow r <= flow demand\n",
    "                model.addConstr(gp.quicksum(x[l, r] for l in range(num_links) if routing_matrix[l, r] == 1) >= 0,\n",
    "                                name=f\"non_negativity_{r}\")\n",
    "\n",
    "            # Optimize the model\n",
    "            model.optimize()\n",
    "\n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                # Extract the solution data\n",
    "                objective_value = model.ObjVal\n",
    "                time_to_solve = model.Runtime\n",
    "                return objective_value, time_to_solve\n",
    "            else:\n",
    "                objective_value = model.ObjVal\n",
    "                time_to_solve = model.Runtime\n",
    "                return objective_value, time_to_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b82122-5e63-4a1a-87c1-d1730c00a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scaled_positive_normal(n, dispersion, loc=1.0, seed=None):\n",
    "    \"\"\"\n",
    "    Generuje n pozytywnych wartości z rozkładu normalnego,\n",
    "    zastępuje wartości negatywne małymi dodatnimi liczbami,\n",
    "    a następnie skaluje je, aby suma wynosiła 1.\n",
    "\n",
    "    :param n: Liczba wartości do wygenerowania\n",
    "    :param dispersion: Odchylenie standardowe rozkładu normalnego\n",
    "    :param loc: Średnia rozkładu normalnego\n",
    "    :param seed: Opcjonalny seed dla powtarzalności\n",
    "    :return: NumPy array z n skalowanymi, dodatnimi wartościami\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    values = np.random.normal(loc=loc, scale=dispersion, size=n)\n",
    "    # Zastąp wartości negatywne małymi dodatnimi liczbami\n",
    "    values = np.where(values > 0, values, 0.01)\n",
    "    scaled_values = values / np.sum(values)\n",
    "    return scaled_values\n",
    "\n",
    "\n",
    "def generate_capacities(n, dispersion, seed=None):\n",
    "    \"\"\"\n",
    "    Generuje n wartości z rozkładu normalnego,\n",
    "    zastępuje wartości mniejsze niż 1 wartością 1.\n",
    "\n",
    "    :param n: Liczba wartości do wygenerowania\n",
    "    :param dispersion: Odchylenie standardowe rozkładu normalnego\n",
    "    :param seed: Opcjonalny seed dla powtarzalności\n",
    "    :return: NumPy array z n pojemnościami >=1\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    values = np.random.normal(loc=10.0, scale=dispersion, size=n)\n",
    "    # Zastąp wartości mniejsze niż 1 wartością 1\n",
    "    values = np.where(values >= 1, values, 1.0)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1197a13-1b0f-43b9-a8b3-dfa7bf9f4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_routing_matrix(num_links, num_flows, sparsity=0.5, seed=None):\n",
    "    \"\"\"\n",
    "    Generuje losową macierz routingu o wymiarach (num_links x num_flows),\n",
    "    zapewniając, że każdy przepływ korzysta z co najmniej jednego połączenia\n",
    "    oraz każde połączenie jest używane przez co najmniej jeden przepływ.\n",
    "\n",
    "    :param num_links: Liczba połączeń\n",
    "    :param num_flows: Liczba przepływów\n",
    "    :param sparsity: Prawdopodobieństwo, że dana komórka będzie wynosić 1\n",
    "    :param seed: Opcjonalny seed dla powtarzalności\n",
    "    :return: NumPy array o wymiarach (num_links x num_flows)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    routing_matrix = np.random.rand(num_links, num_flows) < sparsity\n",
    "    routing_matrix = routing_matrix.astype(int)\n",
    "\n",
    "    # Zapewnij, że każdy przepływ korzysta z co najmniej jednego połączenia\n",
    "    for flow in range(num_flows):\n",
    "        if not routing_matrix[:, flow].any():\n",
    "            link = np.random.randint(0, num_links)\n",
    "            routing_matrix[link, flow] = 1\n",
    "\n",
    "    # Zapewnij, że każde połączenie jest używane przez co najmniej jeden przepływ\n",
    "    for link in range(num_links):\n",
    "        if not routing_matrix[link, :].any():\n",
    "            flow = np.random.randint(0, num_flows)\n",
    "            routing_matrix[link, flow] = 1\n",
    "    return routing_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5536a38-a5a7-461e-8c9c-a50b30e2103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_problem_instance(\n",
    "    links,\n",
    "    flows,\n",
    "    capacity_dispersion,\n",
    "    weight_dispersion,\n",
    "    gamma,\n",
    "    routing_seed=None,\n",
    "    capacity_seed=None,\n",
    "    weight_seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generuje instancję problemu z zadanymi parametrami.\n",
    "\n",
    "    :param links: Liczba połączeń\n",
    "    :param flows: Liczba przepływów\n",
    "    :param capacity_dispersion: Odchylenie standardowe dla pojemności\n",
    "    :param weight_dispersion: Odchylenie standardowe dla wag\n",
    "    :param gamma: Parametr funkcji celu\n",
    "    :param routing_seed: Seed dla macierzy routingu\n",
    "    :param capacity_seed: Seed dla pojemności\n",
    "    :param weight_seed: Seed dla wag\n",
    "    :return: Słownik zawierający wszystkie elementy instancji\n",
    "    \"\"\"\n",
    "    capacities = generate_capacities(links, capacity_dispersion, seed=capacity_seed)\n",
    "    weights = generate_scaled_positive_normal(flows, weight_dispersion, seed=weight_seed)\n",
    "    routing_matrix = generate_routing_matrix(links, flows, seed=routing_seed)\n",
    "\n",
    "    instance = {\n",
    "        'links': links,\n",
    "        'flows': flows,\n",
    "        'capacities': capacities.tolist(),\n",
    "        'weights': weights.tolist(),\n",
    "        'routing_matrix': routing_matrix.tolist(),\n",
    "        'gamma': gamma\n",
    "    }\n",
    "\n",
    "    return instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f6d31b-68c2-4e67-929c-4492d90ab831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_instances():\n",
    "    \"\"\"\n",
    "    Generuje wszystkie instancje testowe, zmieniając jeden parametr na raz.\n",
    "    Dla każdego parametru badane są 3 różne wartości.\n",
    "\n",
    "    :return: Lista słowników z instancjami problemu\n",
    "    \"\"\"\n",
    "    # Definicja wartości bazowych\n",
    "    base_params = {\n",
    "        'gamma': 0.5,\n",
    "        'weight_dispersion': 0.1,\n",
    "        'links': 3,\n",
    "        'flows': 3,\n",
    "        'capacity_dispersion': 1\n",
    "    }\n",
    "\n",
    "    # Seedy dla powtarzalności\n",
    "    base_seed = 420692137\n",
    "    np.random.seed(base_seed)\n",
    "\n",
    "    # Generowanie bazowej instancji\n",
    "    base_instance = generate_problem_instance(\n",
    "        links=base_params['links'],\n",
    "        flows=base_params['flows'],\n",
    "        capacity_dispersion=base_params['capacity_dispersion'],\n",
    "        weight_dispersion=base_params['weight_dispersion'],\n",
    "        gamma=base_params['gamma'],\n",
    "        routing_seed=base_seed,\n",
    "        capacity_seed=base_seed + 1,\n",
    "        weight_seed=base_seed + 2\n",
    "    )\n",
    "\n",
    "    test_instances = []\n",
    "\n",
    "    # Definicja możliwych wartości dla każdego parametru (3 wartości)\n",
    "    param_variations = {\n",
    "        'gamma': [0.3, 0.5, 0.7, 1, 2],\n",
    "        'weight_dispersion': [0, 0.1, 1, 3, 5],\n",
    "        'links': [2, 3, 4, 6, 10],\n",
    "        'flows': [2, 3, 4, 6, 10],\n",
    "        'capacity_dispersion': [0.05, 0.1, 0.2, 0.5, 1]\n",
    "    }\n",
    "\n",
    "    # Iteruj przez każdy parametr\n",
    "    for param, values in param_variations.items():\n",
    "        for value in values:\n",
    "            # Utwórz kopię bazowej instancji\n",
    "            new_instance = copy.deepcopy(base_instance)\n",
    "            # Zmieniony parametr\n",
    "            new_instance['gamma'] = base_params['gamma']  # default\n",
    "            new_instance['weight_dispersion'] = base_params['weight_dispersion']\n",
    "            new_instance['capacity_dispersion'] = base_params['capacity_dispersion']\n",
    "            new_instance['links'] = base_params['links']\n",
    "            new_instance['flows'] = base_params['flows']\n",
    "\n",
    "            # Modyfikacja w zależności od parametru\n",
    "            if param == 'gamma':\n",
    "                new_instance['gamma'] = value\n",
    "            elif param == 'weight_dispersion':\n",
    "                new_instance['weight_dispersion'] = value\n",
    "                # Regeneruj weights\n",
    "                new_weights = generate_scaled_positive_normal(\n",
    "                    base_params['flows'],\n",
    "                    value,\n",
    "                    seed=base_seed + 2\n",
    "                )\n",
    "                new_instance['weights'] = new_weights\n",
    "            elif param == 'capacity_dispersion':\n",
    "                new_instance['capacity_dispersion'] = value\n",
    "                # Regeneruj capacities\n",
    "                new_capacities = generate_capacities(\n",
    "                    base_params['links'],\n",
    "                    value,\n",
    "                    seed=base_seed + 1\n",
    "                )\n",
    "                new_instance['capacities'] = new_capacities\n",
    "            elif param == 'links':\n",
    "                new_instance['links'] = value\n",
    "                # Regeneruj capacities, weights, routing_matrix\n",
    "                new_capacities = generate_capacities(\n",
    "                    value,\n",
    "                    base_params['capacity_dispersion'],\n",
    "                    seed=base_seed + 1\n",
    "                )\n",
    "                new_weights = generate_scaled_positive_normal(\n",
    "                    base_params['flows'],\n",
    "                    base_params['weight_dispersion'],\n",
    "                    seed=base_seed + 2\n",
    "                )\n",
    "                new_routing_matrix = generate_routing_matrix(\n",
    "                    value,\n",
    "                    base_params['flows'],\n",
    "                    seed=base_seed\n",
    "                )\n",
    "                new_instance['capacities'] = new_capacities\n",
    "                new_instance['weights'] = new_weights\n",
    "                new_instance['routing_matrix'] = new_routing_matrix\n",
    "            elif param == 'flows':\n",
    "                new_instance['flows'] = value\n",
    "                # Regeneruj capacities, weights, routing_matrix\n",
    "                new_capacities = generate_capacities(\n",
    "                    base_params['links'],\n",
    "                    base_params['capacity_dispersion'],\n",
    "                    seed=base_seed + 1\n",
    "                )\n",
    "                new_weights = generate_scaled_positive_normal(\n",
    "                    value,\n",
    "                    base_params['weight_dispersion'],\n",
    "                    seed=base_seed + 2\n",
    "                )\n",
    "                new_routing_matrix = generate_routing_matrix(\n",
    "                    base_params['links'],\n",
    "                    value,\n",
    "                    seed=base_seed\n",
    "                )\n",
    "                new_instance['capacities'] = new_capacities\n",
    "                new_instance['weights'] = new_weights\n",
    "                new_instance['routing_matrix'] = new_routing_matrix\n",
    "\n",
    "            # Dodaj informację o zmienionym parametrze\n",
    "            test_instances.append({\n",
    "                'changed_parameter': param,\n",
    "                'changed_value': value,\n",
    "                'instance': new_instance\n",
    "            })\n",
    "\n",
    "    return test_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c3aedb2-0017-4789-90cd-9f9e69ef70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generowanie instancji testowych\n",
    "test_instances = generate_test_instances()\n",
    "results = {\n",
    "    'gamma': [],\n",
    "    'weight_dispersion': [],\n",
    "    'links': [],\n",
    "    'flows': [],\n",
    "    'capacity_dispersion': [],\n",
    "\n",
    "    'capacities': [],\n",
    "    'routing_matrix': [],\n",
    "    'weights': [],\n",
    "    \n",
    "    'time_mean': [],\n",
    "    'time_std_dev': [],\n",
    "    'result_mean': [],\n",
    "    'time_mean_gurobi': [],\n",
    "    'time_std_dev_gurobi': [],\n",
    "    'result_mean_gurobi': []\n",
    "}\n",
    "\n",
    "# Wyświetlenie przykładowych instancji\n",
    "for idx, test in enumerate(test_instances, start=1):\n",
    "    time_mean, time_std_dev, result_mean = capacity_allocation_game(test[\"instance\"][\"links\"],test[\"instance\"][\"capacities\"],np.array(test[\"instance\"][\"routing_matrix\"]),test[\"instance\"][\"weights\"],test[\"instance\"][\"gamma\"])\n",
    "    time_mean_gurobi, time_std_dev_gurobi, result_mean_gurobi = optimize_with_gurobi(test[\"instance\"][\"capacities\"],np.array(test[\"instance\"][\"routing_matrix\"]),test[\"instance\"][\"weights\"],test[\"instance\"][\"gamma\"])\n",
    "    results['gamma'].append(test['instance']['gamma'])\n",
    "    results['weight_dispersion'].append(test['instance']['weight_dispersion'])\n",
    "    results['links'].append(test['instance']['links'])\n",
    "    results['flows'].append(test['instance']['flows'])\n",
    "    results['capacity_dispersion'].append(test['instance']['capacity_dispersion'])\n",
    "    \n",
    "    results['capacities'].append(test[\"instance\"][\"capacities\"])\n",
    "    results['routing_matrix'].append(test[\"instance\"][\"routing_matrix\"])\n",
    "    results['weights'].append(test[\"instance\"][\"weights\"])\n",
    "    \n",
    "    results['time_mean'].append(time_mean)\n",
    "    results['time_std_dev'].append(time_std_dev)\n",
    "    results['result_mean'].append(result_mean)\n",
    "    results['time_mean_gurobi'].append(time_mean_gurobi)\n",
    "    results['time_std_dev_gurobi'].append(time_std_dev_gurobi)\n",
    "    results['result_mean_gurobi'].append(result_mean_gurobi)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19063cc9-db25-4504-8bf9-8280b44969e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
